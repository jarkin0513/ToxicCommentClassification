{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing"
      ],
      "metadata": {
        "id": "otfvpPPMmeBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nH0uQ8CmRa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17d15bb-3ab5-4830-8d82-049884e88007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Training dataset shape: (159571, 8)\n",
            "Test dataset shape: (153164, 2)\n",
            "                                        comment_text  \\\n",
            "0  Explanation\\nWhy the edits made under my usern...   \n",
            "1  D'aww! He matches this background colour I'm s...   \n",
            "2  Hey man, I'm really not trying to edit war. It...   \n",
            "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
            "4  You, sir, are my hero. Any chance you remember...   \n",
            "\n",
            "                                       clean_comment  \n",
            "0  explanation why the edits made under my userna...  \n",
            "1  daww he matches this background colour im seem...  \n",
            "2  hey man im really not trying to edit war its j...  \n",
            "3  more i cant make any real suggestions on impro...  \n",
            "4  you sir are my hero any chance you remember wh...  \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to the zip files in Drive\n",
        "zip_dir = '/content/drive/MyDrive/jigsaw-toxic-comment-classification-challenge/'\n",
        "\n",
        "# Unzip training and testing zips\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_dir + 'train.csv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "with zipfile.ZipFile(zip_dir + 'test.csv.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "# Load CSV files\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "print(\"Training dataset shape:\", train_df.shape)\n",
        "print(\"Test dataset shape:\", test_df.shape)\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)                  # Remove emails\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)                 # Remove special characters and numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()             # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Clean the comments\n",
        "train_df['clean_comment'] = train_df['comment_text'].apply(clean_text)\n",
        "test_df['clean_comment'] = test_df['comment_text'].apply(clean_text)\n",
        "\n",
        "print(train_df[['comment_text', 'clean_comment']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction with TF‑IDF"
      ],
      "metadata": {
        "id": "RxsWidvPmgX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_df['clean_comment'])\n",
        "X_test = vectorizer.transform(test_df['clean_comment'])\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "# Define toxicity labels\n",
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "y_train = train_df[label_cols].values\n"
      ],
      "metadata": {
        "id": "E7aqfahVmV-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2b13a0-0ec3-44e2-d0f2-f18fb9bbb540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (159571, 10000)\n",
            "Shape of X_test: (153164, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train/Validation Split and SVM Training"
      ],
      "metadata": {
        "id": "njg8VzvxmlO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Split the data - 80/20 Split\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up a base LinearSVC and wrap it with calibration for probability estimates\n",
        "base_svm = LinearSVC(random_state=42)\n",
        "\n",
        "# Use CalibratedClassifierCV to get probabilities\n",
        "calibrated_svm = OneVsRestClassifier(CalibratedClassifierCV(base_svm, cv=3))\n",
        "\n",
        "# Train the classifier on the training split\n",
        "calibrated_svm.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_prob = calibrated_svm.predict_proba(X_val)\n",
        "y_val_pred = calibrated_svm.predict(X_val)\n",
        "\n",
        "print(\"Validation predictions shape:\", y_val_pred.shape)\n"
      ],
      "metadata": {
        "id": "MGeSLm-6moRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bef24b-adb9-428c-98b2-f2c08524a25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation predictions shape: (31915, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "_-Yn6F1ymprq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "# Define labels and thresholds\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "optimized_thresholds = {\n",
        "    \"toxic\": 0.5082,\n",
        "    \"severe_toxic\": 0.5408,\n",
        "    \"obscene\": 0.6551,\n",
        "    \"threat\": 0.1,\n",
        "    \"insult\": 0.5082,\n",
        "    \"identity_hate\": 0.1\n",
        "}\n",
        "optimized_thresh_array = np.array([optimized_thresholds[lbl] for lbl in label_cols])\n",
        "print(\"Optimized thresholds array:\", optimized_thresh_array)\n",
        "\n",
        "# Use the predictions from the calibrated classifier\n",
        "all_probs = y_val_prob  # Predicted probabilities for validation set\n",
        "all_labels = y_val      # Ground truth labels\n",
        "\n",
        "# Binarize predictions using thresholds\n",
        "bin_preds = (all_probs >= optimized_thresh_array).astype(int)\n",
        "\n",
        "# Compute per‑label Precision, Recall, and F1 scores\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(all_labels, bin_preds, average=None, zero_division=0)\n",
        "macro_f1 = np.mean(f1)\n",
        "\n",
        "# Compute micro‑averaged metrics\n",
        "micro_p, micro_r, micro_f1, _ = precision_recall_fscore_support(\n",
        "    all_labels.ravel(), bin_preds.ravel(), average=\"micro\", zero_division=0\n",
        ")\n",
        "\n",
        "# Compute subset accuracy\n",
        "subset_acc = accuracy_score(all_labels, bin_preds)\n",
        "\n",
        "# Compute ROC‑AUC and PR‑AUC\n",
        "roc_auc_macro = roc_auc_score(all_labels, all_probs, average=\"macro\")\n",
        "pr_auc_macro = average_precision_score(all_labels, all_probs, average=\"macro\")\n",
        "\n",
        "# Compute and print per‑label Confusion Matrices\n",
        "conf_matrices = {}\n",
        "for i, lbl in enumerate(label_cols):\n",
        "    cm = confusion_matrix(all_labels[:, i], bin_preds[:, i])\n",
        "    conf_matrices[lbl] = cm\n",
        "    print(f\"Confusion matrix for {lbl}:\")\n",
        "    print(cm)\n",
        "    print()\n",
        "\n",
        "# Print Report\n",
        "print(\"\\n===== Evaluation Metrics =====\")\n",
        "for i, lbl in enumerate(label_cols):\n",
        "    print(f\"{lbl:15s}  Precision: {prec[i]:.3f}  Recall: {rec[i]:.3f}  F1: {f1[i]:.3f}\")\n",
        "print(\"-------------------------------------------------\")\n",
        "print(f\"Macro‑F1           : {macro_f1:.4f}\")\n",
        "print(f\"Micro‑F1           : {micro_f1:.4f}\")\n",
        "print(f\"Subset accuracy    : {subset_acc:.4f}\")\n",
        "print(f\"ROC‑AUC (macro)    : {roc_auc_macro:.4f}\")\n",
        "print(f\"PR‑AUC  (macro)    : {pr_auc_macro:.4f}\")\n",
        "print(\"=================================================\\n\")\n"
      ],
      "metadata": {
        "id": "MOq99dlOmtF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03c674f-c025-4691-fe1d-6fec7a3234e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized thresholds array: [0.5082 0.5408 0.6551 0.1    0.5082 0.1   ]\n",
            "Confusion matrix for toxic:\n",
            "[[28600   259]\n",
            " [ 1075  1981]]\n",
            "\n",
            "Confusion matrix for severe_toxic:\n",
            "[[31562    32]\n",
            " [  264    57]]\n",
            "\n",
            "Confusion matrix for obscene:\n",
            "[[30110    90]\n",
            " [  673  1042]]\n",
            "\n",
            "Confusion matrix for threat:\n",
            "[[31770    71]\n",
            " [   36    38]]\n",
            "\n",
            "Confusion matrix for insult:\n",
            "[[30105   196]\n",
            " [  758   856]]\n",
            "\n",
            "Confusion matrix for identity_hate:\n",
            "[[31394   227]\n",
            " [  141   153]]\n",
            "\n",
            "\n",
            "===== Evaluation Metrics =====\n",
            "toxic            Precision: 0.884  Recall: 0.648  F1: 0.748\n",
            "severe_toxic     Precision: 0.640  Recall: 0.178  F1: 0.278\n",
            "obscene          Precision: 0.920  Recall: 0.608  F1: 0.732\n",
            "threat           Precision: 0.349  Recall: 0.514  F1: 0.415\n",
            "insult           Precision: 0.814  Recall: 0.530  F1: 0.642\n",
            "identity_hate    Precision: 0.403  Recall: 0.520  F1: 0.454\n",
            "-------------------------------------------------\n",
            "Macro‑F1           : 0.5449\n",
            "Micro‑F1           : 0.9800\n",
            "Subset accuracy    : 0.9157\n",
            "ROC‑AUC (macro)    : 0.9672\n",
            "PR‑AUC  (macro)    : 0.6201\n",
            "=================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}